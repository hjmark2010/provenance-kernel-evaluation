{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Flat Provenance Types and Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requiring Python packages: requests, prov\n",
    "import requests\n",
    "from prov.model import ProvDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to produce flat provenance types is provided in [flatprovenancetypes.py](flatprovenancetypes.py). We import the function `calculate_flat_provenance_types` contained therein to use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flatprovenancetypes import calculate_flat_provenance_types, print_flat_type, count_fp_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_prov_json_document(url: str) -> ProvDocument:\n",
    "    # try to download the provided url\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    # no exception so far, we have successfuly downloaded it\n",
    "    prov_doc = ProvDocument.deserialize(content=r.text)\n",
    "    return prov_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing flat provenance types\n",
    "\n",
    "In this example, we use a public PROV document at https://openprovenance.org/store/documents/282."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the .json extension at the end of the URL.\n",
    "prov_doc = download_prov_json_document(\"https://openprovenance.org/store/documents/282.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the command below, we produce the flat provenance types for every nodes in the input ProvDocument object (a node in a provenance graph is either an entity, an agent, or an activity). We will produce types up to level 2 and ignore all application-specific types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fptypes = calculate_flat_provenance_types(\n",
    "    prov_doc,  # the ProvDocument object to produce types from\n",
    "    to_level=2,  # calculate types up to this given level (2)\n",
    "    including_primitives_types=False,  # only consider PROV generic types, ignoring application-specific types\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned `fptypes` structure contains 0-types for all nodes in `fptypes[0]`, 1-types in `fptypes[1]`, and so on, up to the specified level in the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fptypes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each level, we have a map of node to its type in that level. For example, if we look at level 1, the map contains all the identifiers of the nodes found in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instructions/InfrastructureDamage529-1761.2: [gen|spe]→[act|ent]\n",
      "transporter272.2: [gen]→[act]\n",
      "uav/target/9.2: [att|der|gen]→[act|agt|ent]\n",
      "instructions/InfrastructureDamage529-1762.2: [gen|spe]→[act|ent]\n",
      "medic273.2: [gen]→[act]\n",
      "instructions/InfrastructureDamage529-1761: [der]→[ent]\n",
      "instructions/InfrastructureDamage529-1762: [der]→[ent]\n",
      "cs/target/9.0: [att|der|spe]→[agt|ent]\n",
      "activity/AcceptInstruction1761: [usd]→[ent]\n",
      "cs/target/9.1: [att|der|spe]→[agt|ent]\n",
      "instructions/InfrastructureDamage529-1762.1: [spe]→[ent]\n",
      "instructions/InfrastructureDamage529-1761.1: [spe]→[ent]\n",
      "InfrastructureDamage529: [der]→[ent]\n",
      "confirmed_plans/166: [mem]→[ent]\n",
      "activity/uav_verification/1411560570.812: [usd|waw]→[agt|ent]\n",
      "activity/AcceptInstruction1762: [usd]→[ent]\n",
      "cs/report/43: [att]→[agt]\n",
      "cs/report/64: [att]→[agt]\n",
      "cs/report/2: [att]→[agt]\n",
      "cs/report/16: [att]→[agt]\n",
      "cs/report/33: [att]→[agt]\n"
     ]
    }
   ],
   "source": [
    "for node_identifier, fptype in fptypes[1].items():\n",
    "    print(f\"{node_identifier}: {print_flat_type(fptype)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print_flat_type` function above is a utility function to print flat provenance types in an easy-to-read representation, similar to how they are presented in [our paper](https://arxiv.org/abs/2010.10343)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating feature vectors\n",
    "\n",
    "With a given provenance document, we calculate the types and then count the occurences of each type we see. The numbers of occurences for all flat provenance types in that document are then used as the feature vector for it.\n",
    "\n",
    "Using the provenance graph above and the `fptypes` structure we already calculated from it, assumming that we want to count only 0-types, we can generate the feature vector for level 0 as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[act]': 3, '[ent]': 19, '[agt]': 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_fp_types(fptypes[0].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we only use the `.values()` of the map (a Python `dict` in this case) because we care only the types of the nodes, not the their identifiers (which are the \"keys\" of the map).\n",
    "\n",
    "The result we see above is the sparse representation of a vector `(3, 19, 5)` for features `[act]`, `[ent]`, and `[agt]`, respectively. Since we do not know beforehand how many different features we will actually see from a provenance document, it is not possible to define the dimension of the feature vector, hence the need to use the sparse representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above statement, we only count 0-types. If we want to produce a feature vector to contain all types up to, say, level 2, we can merge all the types of the desired levels before counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[act]': 3,\n",
       " '[ent]': 19,\n",
       " '[agt]': 5,\n",
       " '[gen|spe]→[act|ent]': 2,\n",
       " '[gen]→[act]': 2,\n",
       " '[att|der|gen]→[act|agt|ent]': 1,\n",
       " '[der]→[ent]': 3,\n",
       " '[att|der|spe]→[agt|ent]': 2,\n",
       " '[usd]→[ent]': 2,\n",
       " '[spe]→[ent]': 2,\n",
       " '[mem]→[ent]': 1,\n",
       " '[usd|waw]→[agt|ent]': 1,\n",
       " '[att]→[agt]': 5,\n",
       " '[mem]→[gen|spe]→[act|ent]': 1,\n",
       " '[der]→[att|der|gen]→[act|agt|ent]': 1,\n",
       " '[spe]→[der]→[ent]': 2,\n",
       " '[gen|spe]→[der|usd]→[ent]': 2,\n",
       " '[der]→[att|der|spe]→[agt|ent]': 1,\n",
       " '[gen]→[usd]→[ent]': 2,\n",
       " '[usd]→[att|der|spe]→[agt|ent]': 1,\n",
       " '[der|gen]→[att|der|spe|usd|waw]→[agt|ent]': 1,\n",
       " '[usd]→[spe]→[ent]': 2,\n",
       " '[der]→[der]→[ent]': 2,\n",
       " '[der]→[att]→[agt]': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_fp_types(\n",
    "    chain.from_iterable(fpt_level.values() for fpt_level in fptypes.values())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the code above into a single function, we can produce the (sparse) feature vector from a provenance document with the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_feature_vector(\n",
    "    prov_doc: ProvDocument, \n",
    "    to_level: int = 0,\n",
    "    including_primitives_types: bool = True\n",
    ") -> Dict[str, int]:\n",
    "    \n",
    "    fptypes = calculate_flat_provenance_types(prov_doc, to_level, including_primitives_types)\n",
    "    return count_fp_types(\n",
    "        chain.from_iterable(fpt_level.values() for fpt_level in fptypes.values())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[act]': 3,\n",
       " '[ent|ao:InfrastructureDamage]': 1,\n",
       " '[ent]': 15,\n",
       " '[ent|ao:Instruction]': 2,\n",
       " '[ent|ao:Plan]': 1,\n",
       " '[agt|ao:CrowdReporter|prov:Person]': 3,\n",
       " '[agt|ao:IBCCAlgo|prov:SoftwareAgent]': 1,\n",
       " '[agt|prov:Person]': 1,\n",
       " '[gen|spe]→[act|ent|ao:Instruction]': 2,\n",
       " '[gen]→[act]': 2,\n",
       " '[att|der|gen]→[act|agt|ent|prov:Person]': 1,\n",
       " '[der]→[ent|ao:InfrastructureDamage]': 2,\n",
       " '[att|der|spe]→[agt|ent|ao:IBCCAlgo|prov:SoftwareAgent]': 2,\n",
       " '[usd]→[ent]': 2,\n",
       " '[spe]→[ent|ao:Instruction]': 2,\n",
       " '[der]→[ent]': 1,\n",
       " '[mem]→[ent]': 1,\n",
       " '[usd|waw]→[agt|ent|prov:Person]': 1,\n",
       " '[att]→[agt|ao:CrowdReporter|prov:Person]': 5,\n",
       " '[mem]→[gen|spe]→[act|ent|ao:Instruction]': 1,\n",
       " '[der]→[att|der|gen]→[act|agt|ent|prov:Person]': 1,\n",
       " '[spe]→[der]→[ent|ao:InfrastructureDamage]': 2,\n",
       " '[gen|spe]→[der|usd]→[ent|ao:InfrastructureDamage]': 2,\n",
       " '[der]→[att|der|spe]→[agt|ent|ao:CrowdReporter|ao:IBCCAlgo|prov:Person|prov:SoftwareAgent]': 1,\n",
       " '[gen]→[usd]→[ent]': 2,\n",
       " '[usd]→[att|der|spe]→[agt|ent|ao:IBCCAlgo|prov:SoftwareAgent]': 1,\n",
       " '[der|gen]→[att|der|spe|usd|waw]→[agt|ent|ao:IBCCAlgo|prov:Person|prov:SoftwareAgent]': 1,\n",
       " '[usd]→[spe]→[ent|ao:Instruction]': 2,\n",
       " '[der]→[der]→[ent]': 2,\n",
       " '[der]→[att]→[agt|ao:CrowdReporter|prov:Person]': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_feature_vector(prov_doc, to_level=2, including_primitives_types=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
